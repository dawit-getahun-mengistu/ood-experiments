{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10029120,"sourceType":"datasetVersion","datasetId":6176571}],"dockerImageVersionId":30786,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndatasets_path = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        datasets_path.append(os.path.join(dirname, filename))\n        \n# datasets_path\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:09.086963Z","iopub.execute_input":"2024-12-01T09:36:09.087383Z","iopub.status.idle":"2024-12-01T09:36:09.515818Z","shell.execute_reply.started":"2024-12-01T09:36:09.087344Z","shell.execute_reply":"2024-12-01T09:36:09.514551Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# function, input: dataset, model, output: accuracy of the model over the given dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:09.578972Z","iopub.execute_input":"2024-12-01T09:36:09.579559Z","iopub.status.idle":"2024-12-01T09:36:09.585860Z","shell.execute_reply.started":"2024-12-01T09:36:09.579512Z","shell.execute_reply":"2024-12-01T09:36:09.584324Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.utils import make_grid\nfrom sklearn.model_selection import train_test_split\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:09.588522Z","iopub.execute_input":"2024-12-01T09:36:09.588991Z","iopub.status.idle":"2024-12-01T09:36:13.461348Z","shell.execute_reply.started":"2024-12-01T09:36:09.588933Z","shell.execute_reply":"2024-12-01T09:36:13.459978Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"train_dataset = pd.read_csv('/kaggle/input/fashinemnist-color-sampling/fashion-mnist_train_rgb.csv')\n\ntrain_dataset.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:13.463031Z","iopub.execute_input":"2024-12-01T09:36:13.463803Z","iopub.status.idle":"2024-12-01T09:36:37.650697Z","shell.execute_reply.started":"2024-12-01T09:36:13.463747Z","shell.execute_reply":"2024-12-01T09:36:37.649573Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"(60000, 2353)"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"# construct the models, models with 2, 3, 4 & 6 layers, \nclass MLP2(nn.Module):\n    def __init__(self):\n        super(MLP2, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(2352, 512),  # First hidden layer with 512 neurons\n            nn.ReLU(),\n            nn.Linear(512, 256),   # Second hidden layer with 256 neurons\n            nn.ReLU(),\n            nn.Linear(256, 10)     # Output layer with 10 neurons\n        )\n        \n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\nclass MLP3(nn.Module):\n    def __init__(self):\n        super(MLP3, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(2352, 1024),  # First hidden layer\n            nn.ReLU(),\n            nn.Linear(1024, 512),   # Second hidden layer\n            nn.ReLU(),\n            nn.Linear(512, 256),    # Third hidden layer\n            nn.ReLU(),\n            nn.Linear(256, 10)      # Output layer\n        )\n        \n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\nclass MLP4(nn.Module):\n    def __init__(self):\n        super(MLP4, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(2352, 1024),  # First hidden layer\n            nn.ReLU(),\n            nn.Linear(1024, 512),   # Second hidden layer\n            nn.ReLU(),\n            nn.Linear(512, 256),    # Third hidden layer\n            nn.ReLU(),\n            nn.Linear(256, 128),    # Fourth hidden layer\n            nn.ReLU(),\n            nn.Linear(128, 10)      # Output layer\n        )\n        \n    def forward(self, x):\n        x = self.layers(x)\n        return x\n\nclass MLP6(nn.Module):\n    def __init__(self):\n        super(MLP6, self).__init__()\n        self.layers = nn.Sequential(\n            nn.Linear(2352, 2048),  # First hidden layer\n            nn.ReLU(),\n            nn.Linear(2048, 1024),  # Second hidden layer\n            nn.ReLU(),\n            nn.Linear(1024, 512),   # Third hidden layer\n            nn.ReLU(),\n            nn.Linear(512, 256),    # Fourth hidden layer\n            nn.ReLU(),\n            nn.Linear(256, 128),    # Fifth hidden layer\n            nn.ReLU(),\n            nn.Linear(128, 64),     # Sixth hidden layer\n            nn.ReLU(),\n            nn.Linear(64, 10)       # Output layer\n        )\n        \n    def forward(self, x):\n        x = self.layers(x)\n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:37.653103Z","iopub.execute_input":"2024-12-01T09:36:37.653532Z","iopub.status.idle":"2024-12-01T09:36:37.667276Z","shell.execute_reply.started":"2024-12-01T09:36:37.653487Z","shell.execute_reply":"2024-12-01T09:36:37.666056Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"# define data-loader function\ndef load_train_data(dataset_path):\n    train_df = pd.read_csv(dataset_path)\n    print(train_df.shape)\n    X_train, X_valid, y_train, y_valid = train_test_split(\n        train_df.iloc[:, 1:], train_df['label'], test_size=1/6, random_state=42)\n    \n    transform_train = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(10),\n        transforms.ToTensor()\n    ])\n    transform_test = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor()\n    ])\n\n    # Convert data to tensors\n    X_train_tensor = torch.tensor(X_train.values, dtype=torch.uint8).view(-1, 3,28, 28)\n    y_train_tensor = torch.tensor(y_train.values, dtype=torch.long)\n    X_valid_tensor = torch.tensor(X_valid.values, dtype=torch.uint8).view(-1, 3,28, 28)\n    y_valid_tensor = torch.tensor(y_valid.values, dtype=torch.long)\n\n    # Apply transformation\n    X_train_tensor = torch.stack([transform_train(img) for img in X_train_tensor])\n    X_valid_tensor = torch.stack([transform_test(img) for img in X_valid_tensor])\n    \n    # Flatten the tensors\n    X_train_tensor = X_train_tensor.view(X_train_tensor.size(0), -1)\n    X_valid_tensor = X_valid_tensor.view(X_valid_tensor.size(0), -1)\n\n    # Create TensorDatasets\n    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n    valid_dataset = TensorDataset(X_valid_tensor, y_valid_tensor)\n\n    # Create DataLoaders\n    train_loader = DataLoader(dataset=train_dataset, batch_size=128, shuffle=True)\n    valid_loader = DataLoader(dataset=valid_dataset, batch_size=128, shuffle=False)\n\n    return train_loader\n\ndef load_test_data(dataset_path):\n    test_df = pd.read_csv(dataset_path)\n    X_test = test_df.iloc[:, 1:]\n    \n    transform_test = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.ToTensor()\n    ])\n\n    X_test_tensor = torch.tensor(X_test.values, dtype=torch.uint8).view(-1, 3, 28, 28)\n    X_test_tensor = torch.stack([transform_test(img) for img in X_test_tensor])\n    X_test_tensor = X_test_tensor.view(X_test_tensor.size(0), -1)\n    test_dataset = TensorDataset(X_test_tensor)\n    test_loader = DataLoader(dataset=test_dataset, batch_size=128, shuffle=False)\n\n    return test_loader","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:37.669128Z","iopub.execute_input":"2024-12-01T09:36:37.669676Z","iopub.status.idle":"2024-12-01T09:36:37.692315Z","shell.execute_reply.started":"2024-12-01T09:36:37.669625Z","shell.execute_reply":"2024-12-01T09:36:37.690717Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def test_class_values(dataset_path):\n    test_df = pd.read_csv(dataset_path)\n    y_test = test_df.iloc[:, 0]\n    y_test_tensor = torch.tensor(y_test.values, dtype=torch.long)\n\n    return y_test_tensor","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:37.693955Z","iopub.execute_input":"2024-12-01T09:36:37.694340Z","iopub.status.idle":"2024-12-01T09:36:37.712838Z","shell.execute_reply.started":"2024-12-01T09:36:37.694297Z","shell.execute_reply":"2024-12-01T09:36:37.711413Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"test_loader = load_test_data('/kaggle/input/fashinemnist-color-sampling/fashion-mnist_test_rgb.csv')\ny_test_tensor = test_class_values('/kaggle/input/fashinemnist-color-sampling/fashion-mnist_test_rgb.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:36:37.714325Z","iopub.execute_input":"2024-12-01T09:36:37.714831Z","iopub.status.idle":"2024-12-01T09:36:44.515677Z","shell.execute_reply.started":"2024-12-01T09:36:37.714772Z","shell.execute_reply":"2024-12-01T09:36:44.514421Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# write the train function\n\ndef train(data_loader, model, epochs):\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    loss_fn = nn.CrossEntropyLoss()\n    model.train()\n    for epoch in range(epochs):\n        for i, (images, labels) in enumerate(train_loader):\n        \n            optimizer.zero_grad()\n            \n            outputs = model(images)\n            loss = loss_fn(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n\n\ndef test(model, test_loader, y_test_tensor):\n    # Set model to evaluation mode\n    model.eval()\n    test_preds = []\n\n    # Disable gradient calculations\n    with torch.no_grad():\n        for batch in test_loader:  # Each batch is a list containing one tensor\n            images = batch[0].to(next(model.parameters()).device)  # Extract the tensor and move to device\n\n            # Forward pass\n            outputs = model(images)\n\n            # Get predictions\n            pred = outputs.max(1, keepdim=True)[1]\n            test_preds.append(pred.cpu())  # Store predictions on CPU for safety\n\n    # Concatenate all predictions\n    test_preds = torch.cat(test_preds).view(-1)\n    y_test_tensor = y_test_tensor.view(-1)\n\n    # Calculate accuracy\n    correct = (test_preds == y_test_tensor).sum().item()\n    total = y_test_tensor.size(0)\n    accuracy = 100 * correct / total\n\n    return accuracy\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:08:25.474986Z","iopub.execute_input":"2024-12-01T10:08:25.475480Z","iopub.status.idle":"2024-12-01T10:08:25.486111Z","shell.execute_reply.started":"2024-12-01T10:08:25.475427Z","shell.execute_reply":"2024-12-01T10:08:25.484903Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# run the train function for all (dataset, model) pair\ntrain_dataset_loaders = [load_train_data(path) for path in datasets_path]\nmodels = [MLP2, MLP3, MLP4, MLP6]\nresult = {}\n\n\nepoch = 10\nfor i, train_loader in enumerate(train_dataset_loaders):\n    for model in models:\n        model = model()\n        train(train_loader, model, epoch)\n        res = test(model, test_loader, y_test_tensor)\n\n        result[(datasets_path[i], models[i])] = res\n    ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"for i, train_loader in enumerate(train_dataset_loaders):\n    for model in models:\n        model = model()\n        train(train_loader, model, epoch)\n        res = test(model, test_loader, y_test_tensor)\n\n        result[(datasets_path[i], models[i])] = res","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T10:08:29.804811Z","iopub.execute_input":"2024-12-01T10:08:29.805219Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Analyse and interpret \"result\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-12-01T09:41:24.281278Z","iopub.status.idle":"2024-12-01T09:41:24.281682Z","shell.execute_reply.started":"2024-12-01T09:41:24.281495Z","shell.execute_reply":"2024-12-01T09:41:24.281519Z"}},"outputs":[],"execution_count":null}]}