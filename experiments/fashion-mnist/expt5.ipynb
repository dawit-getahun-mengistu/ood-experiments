{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "os.chdir('../../experiments')\n",
    "\n",
    "# print(\"Current working directory:\", os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms, utils\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms.functional as F\n",
    "import random\n",
    "\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CustomColoredFashionMNIST', 'FashionMNIST', 'MNIST']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "directory = \"../data\"\n",
    "files = os.listdir(directory)\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_transform = transforms.Compose([\n",
    "    # Convert grayscale to 3-channel RGB\n",
    "    transforms.Grayscale(num_output_channels=3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "                         )  # Normalize for 3 channels\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch_size = 64\n",
    "test_batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "grey_train_dataset = datasets.FashionMNIST(\n",
    "    directory, train=True, download=True, transform=grey_transform)\n",
    "\n",
    "grey_test_dataset = datasets.FashionMNIST(\n",
    "    directory, train=False, transform=grey_transform)\n",
    "\n",
    "grey_train_loader = DataLoader(\n",
    "    grey_train_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "grey_test_loader = DataLoader(\n",
    "    grey_test_dataset, batch_size=test_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image shape: torch.Size([3, 28, 28]), Label: 9\n"
     ]
    }
   ],
   "source": [
    "sample_image, sample_label = grey_train_dataset[0]\n",
    "print(f\"Sample image shape: {sample_image.shape}, Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "grey_transform = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=3),  # Ensure 3 channels for input\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)\n",
    "                         )  # Normalize for 3 channels\n",
    "])\n",
    "\n",
    "\n",
    "class_colors = [\n",
    "    (255, 0, 0),  # Red for class 0\n",
    "    (0, 255, 0),  # Green for class 1\n",
    "    (0, 0, 255),  # Blue for class 2\n",
    "    (255, 255, 0),  # Yellow for class 3\n",
    "    (255, 0, 255),  # Magenta for class 4\n",
    "    (0, 255, 255),  # Cyan for class 5\n",
    "    (128, 128, 128),  # Gray for class 6\n",
    "    (255, 128, 0),  # Orange for class 7\n",
    "    (128, 0, 255),  # Purple for class 8\n",
    "    (0, 128, 255),  # Sky blue for class 9\n",
    "]\n",
    "\n",
    "swapped_class_colors = [\n",
    "    (0, 255, 0),  # Green for class 0\n",
    "    (255, 0, 0),  # Red for class 1\n",
    "\n",
    "    (255, 255, 0),  # Yellow for class 2\n",
    "    (0, 0, 255),  # Blue for class 3\n",
    "\n",
    "    (0, 255, 255),  # Cyan for class 4\n",
    "    (255, 0, 255),  # Magenta for class 5\n",
    "\n",
    "    (255, 128, 0),  # Orange for class 6\n",
    "    (128, 128, 128),  # Gray for class 7\n",
    "\n",
    "    (0, 128, 255),  # Sky blue for class 8\n",
    "    (128, 0, 255),  # Purple for class 9\n",
    "\n",
    "]\n",
    "\n",
    "fashion_mnist_classes = [\n",
    "    \"T-shirt/top\", \"Trouser\", \"Pullover\", \"Dress\", \"Coat\",\n",
    "    \"Sandal\", \"Shirt\", \"Sneaker\", \"Bag\", \"Ankle boot\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ColoredFashionMNIST(Dataset):\n",
    "    def __init__(self, dataset, class_colors, transform=None):\n",
    "        \"\"\"\n",
    "        Custom dataset for FashionMNIST with class-based coloring.\n",
    "\n",
    "        Args:\n",
    "        - dataset: Torchvision dataset (e.g., FashionMNIST).\n",
    "        - class_colors: List of RGB tuples for each class.\n",
    "        - transform: Torchvision transforms to apply to the images.\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.class_colors = class_colors\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the grayscale image and label\n",
    "        image, label = self.dataset[idx]\n",
    "\n",
    "        # Apply the transformation (if provided)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert grayscale to colored\n",
    "        colored_image = self.grayscale_to_colored(image, label)\n",
    "\n",
    "        return colored_image, label\n",
    "\n",
    "    def grayscale_to_colored(self, image, label):\n",
    "        \"\"\"\n",
    "        Converts a transformed 3-channel normalized tensor to class-colored RGB tensor.\n",
    "\n",
    "        Args:\n",
    "        - image: Tensor of shape (3, H, W) with values normalized to (-1, 1).\n",
    "        - label: Class label to determine color.\n",
    "\n",
    "        Returns:\n",
    "        - colored_image: Tensor of shape (3, H, W) with class-specific coloring.\n",
    "        \"\"\"\n",
    "        # De-normalize to range [0, 1]\n",
    "        image = (image * 0.5) + 0.5\n",
    "\n",
    "        # Get the RGB color for the class\n",
    "        color = torch.tensor(\n",
    "            self.class_colors[label], dtype=torch.float32) / 255.0\n",
    "\n",
    "        # Scale the image by the class color\n",
    "        colored_image = image * color.view(3, 1, 1)\n",
    "\n",
    "        return colored_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample image shape: torch.Size([3, 28, 28]), Label: 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "train_fashion_mnist = datasets.FashionMNIST(\n",
    "    root=directory,\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=None\n",
    ")\n",
    "test_fashion_mnist = datasets.FashionMNIST(\n",
    "    root=directory,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=None\n",
    ")\n",
    "\n",
    "\n",
    "train_colored_dataset = ColoredFashionMNIST(\n",
    "    train_fashion_mnist, class_colors, transform=grey_transform)\n",
    "test_colored_dataset = ColoredFashionMNIST(\n",
    "    test_fashion_mnist, class_colors, transform=grey_transform)\n",
    "test_swapped_colored_dataset = ColoredFashionMNIST(\n",
    "    test_fashion_mnist, swapped_class_colors, transform=grey_transform\n",
    ")\n",
    "\n",
    "sample_image, sample_label = train_colored_dataset[0]\n",
    "print(f\"Sample image shape: {sample_image.shape}, Label: {sample_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "colored_train_loader = DataLoader(\n",
    "    train_colored_dataset, batch_size=train_batch_size, shuffle=True)\n",
    "colored_test_loader = DataLoader(\n",
    "    test_colored_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "swapped_colors_test_loader = DataLoader(\n",
    "    test_swapped_colored_dataset, batch_size=test_batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images_from_loader(loader, classes=fashion_mnist_classes, n_images=64):\n",
    "\n",
    "    # Get a batch of images and labels\n",
    "    images, labels = next(iter(loader))\n",
    "\n",
    "    # Select n_images from the batch\n",
    "    # print(labels)\n",
    "    images, labels = images[:n_images], labels[:n_images]\n",
    "\n",
    "    # Create a grid of images\n",
    "    grid = utils.make_grid(images, nrow=int(\n",
    "        n_images**0.5), padding=2, normalize=True)\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    # Convert from (C, H, W) to (H, W, C) for plotting\n",
    "    plt.imshow(grid.permute(1, 2, 0))\n",
    "    plt.axis('off')\n",
    "    plt.title(\"Sample Images from Dataset\")\n",
    "\n",
    "    for i, label in enumerate(labels):\n",
    "        row, col = divmod(i, int(n_images**0.5))\n",
    "        plt.text(col * (grid.size(2) / n_images**0.5) + 5,\n",
    "                 row * (grid.size(1) / n_images**0.5) + 5,\n",
    "                 classes[label.item()],\n",
    "                 color='white', fontsize=9, ha='center', bbox=dict(facecolor='black', alpha=0.6))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 28, 28]) <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(colored_train_loader))\n",
    "# pick the first image\n",
    "image = images[0]\n",
    "print(image.shape, type(image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(1.), tensor(0.), tensor(0.1355), tensor(0.2472))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image.max(), image.min(), image.mean(), image.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "\n",
    "def plt_image(image):\n",
    "    plt_image = image.permute(1, 2, 0).numpy()\n",
    "    plt.imshow(plt_image)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plt_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers). Got range [0.0..1.5].\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "og_image = images[0].clone()\n",
    "\n",
    "\n",
    "def rgb_normalize(img):\n",
    "    h, w = img.shape[1], img.shape[2]\n",
    "    for i in range(h):\n",
    "        for j in range(w):\n",
    "            R = img[0][i][j]\n",
    "            G = img[1][i][j]\n",
    "            B = img[2][i][j]\n",
    "            # value = (R + G + B) / 3\n",
    "            value = R + G + B\n",
    "            img[0][i][j] = R/value\n",
    "            img[1][i][j] = G/value\n",
    "            img[2][i][j] = B/value\n",
    "    return img\n",
    "\n",
    "\n",
    "rgb_normalized_image = rgb_normalize(image)\n",
    "plt_image(rgb_normalized_image)\n",
    "plt_image(og_image + rgb_normalized_image)\n",
    "plt_image(og_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
